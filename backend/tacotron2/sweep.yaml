program: goat_finetune.py 
method: bayes # Or random, grid
metric:
  name: val/loss # Metric to optimize (MUST match the name logged in train.py)
  goal: minimize
parameters:
  # --- Optimization ---
  learning_rate:
    distribution: log_uniform_values
    min: 1e-5
    max: 1e-3
  batch_size:
    values: [16, 32] # Adjust based on GPU memory

  # --- Regularization ---
  weight_decay:
    distribution: log_uniform_values
    min: 1e-7
    max: 1e-5
  p_attention_dropout:
    values: [0.05, 0.1, 0.15]
  p_decoder_dropout:
    values: [0.05, 0.1, 0.15]

  # --- Early Stopping ---
  early_stopping_patience:
    values: [8, 10, 15]


