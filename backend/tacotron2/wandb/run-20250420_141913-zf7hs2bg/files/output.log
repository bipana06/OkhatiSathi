--- Starting W&B Run: super-deluge-12 (ID: zf7hs2bg) ---
Sweep Configuration for this run:
Run-specific Output Directory: ./outdir_sweep/zf7hs2bg
--- Final HParams for Training Run ---
  epochs: 200
  seed: 1234
  distributed_run: False
  n_gpus: 1
  rank: 0
  group_name: group_name
  cudnn_enabled: True
  cudnn_benchmark: False
  fp16_run: False
  load_mel_from_disk: False
  training_files: ./filelists/train_list.txt
  validation_files: ./filelists/val_list.txt
  text_cleaners: ['transliteration_cleaners']
  num_workers: 4
  pin_memory: True
  max_wav_value: 32768.0
  sampling_rate: 22050
  filter_length: 1024
  hop_length: 256
  win_length: 1024
  n_mel_channels: 80
  mel_fmin: 0.0
  mel_fmax: 8000.0
  n_symbols: 148
  symbols_embedding_dim: 512
  encoder_kernel_size: 5
  encoder_n_convolutions: 3
  encoder_embedding_dim: 512
  n_frames_per_step: 1
  decoder_rnn_dim: 1024
  prenet_dim: 256
  max_decoder_steps: 1000
  gate_threshold: 0.5
  p_attention_dropout: 0.1
  p_decoder_dropout: 0.1
  attention_rnn_dim: 1024
  attention_dim: 128
  attention_location_n_filters: 32
  attention_location_kernel_size: 31
  postnet_embedding_dim: 512
  postnet_kernel_size: 5
  postnet_n_convolutions: 5
  use_saved_learning_rate: False
  learning_rate: 0.0001
  weight_decay: 1e-06
  grad_clip_thresh: 1.0
  batch_size: 32
  mask_padding: True
  log_interval: 100
  iters_per_checkpoint: 1000
  early_stopping_patience: 10
  min_val_loss_delta: 0.0001
  ignore_layers: ['embedding.weight']
--------------------------------------
Calling train function...
/scratch/md5121/okhatisathi/tacotron2/stft.py:67: FutureWarning: Pass size=1024 as keyword args. From version 0.10 passing these as positional arguments will result in an error
  fft_window = pad_center(fft_window, filter_length)
/scratch/md5121/okhatisathi/tacotron2/layers.py:51: FutureWarning: Pass sr=22050, n_fft=1024, n_mels=80, fmin=0.0, fmax=8000.0 as keyword args. From version 0.10 passing these as positional arguments will result in an error
  sampling_rate, filter_length, n_mel_channels, mel_fmin, mel_fmax)
TensorBoard Log directory: ./outdir_sweep/zf7hs2bg/logs
Warm starting model from checkpoint 'tacotron2_statedict.pt'
  Applying warm start: Ignored 1 keys based on ignore_layers. Loading 83 keys.
Warm start complete. Optimizer and iteration count reset.
Starting training for 200 epochs...
--- Epoch: 0 ---
/home/md5121/.conda/envs/t2env/lib/python3.6/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
Train Iter: 0 Epoch: 0 [0/2367 (0%)]	Loss: 1.443230	Grad Norm: 10.358627	LR: 1.0E-04	Time: 9.77s/it