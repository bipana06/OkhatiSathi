Weights & Biases tracking enabled.
FP16 Run: False
Dynamic Loss Scaling: True
Distributed Run: False
cuDNN Enabled: True
cuDNN Benchmark: False
Loading checkpoint 'tacotron2_statedict.pt'
An error occurred during training: Error(s) in loading state_dict for Tacotron2:
	Missing key(s) in state_dict: "embedding.weight", "encoder.convolutions.0.0.conv.weight", "encoder.convolutions.0.0.conv.bias", "encoder.convolutions.0.1.weight", "encoder.convolutions.0.1.bias", "encoder.convolutions.0.1.running_mean", "encoder.convolutions.0.1.running_var", "encoder.convolutions.1.0.conv.weight", "encoder.convolutions.1.0.conv.bias", "encoder.convolutions.1.1.weight", "encoder.convolutions.1.1.bias", "encoder.convolutions.1.1.running_mean", "encoder.convolutions.1.1.running_var", "encoder.convolutions.2.0.conv.weight", "encoder.convolutions.2.0.conv.bias", "encoder.convolutions.2.1.weight", "encoder.convolutions.2.1.bias", "encoder.convolutions.2.1.running_mean", "encoder.convolutions.2.1.running_var", "encoder.lstm.weight_ih_l0", "encoder.lstm.weight_hh_l0", "encoder.lstm.bias_ih_l0", "encoder.lstm.bias_hh_l0", "encoder.lstm.weight_ih_l0_reverse", "encoder.lstm.weight_hh_l0_reverse", "encoder.lstm.bias_ih_l0_reverse", "encoder.lstm.bias_hh_l0_reverse", "decoder.prenet.layers.0.linear_layer.weight", "decoder.prenet.layers.1.linear_layer.weight", "decoder.attention_rnn.weight_ih", "decoder.attention_rnn.weight_hh", "decoder.attention_rnn.bias_ih", "decoder.attention_rnn.bias_hh", "decoder.attention_layer.query_layer.linear_layer.weight", "decoder.attention_layer.memory_layer.linear_layer.weight", "decoder.attention_layer.v.linear_layer.weight", "decoder.attention_layer.location_layer.location_conv.conv.weight", "decoder.attention_layer.location_layer.location_dense.linear_layer.weight", "decoder.decoder_rnn.weight_ih", "decoder.decoder_rnn.weight_hh", "decoder.decoder_rnn.bias_ih", "decoder.decoder_rnn.bias_hh", "decoder.linear_projection.linear_layer.weight", "decoder.linear_projection.linear_layer.bias", "decoder.gate_layer.linear_layer.weight", "decoder.gate_layer.linear_layer.bias", "postnet.convolutions.0.0.conv.weight", "postnet.convolutions.0.0.conv.bias", "postnet.convolutions.0.1.weight", "postnet.convolutions.0.1.bias", "postnet.convolutions.0.1.running_mean", "postnet.convolutions.0.1.running_var", "postnet.convolutions.1.0.conv.weight", "postnet.convolutions.1.0.conv.bias", "postnet.convolutions.1.1.weight", "postnet.convolutions.1.1.bias", "postnet.convolutions.1.1.running_mean", "postnet.convolutions.1.1.running_var", "postnet.convolutions.2.0.conv.weight", "postnet.convolutions.2.0.conv.bias", "postnet.convolutions.2.1.weight", "postnet.convolutions.2.1.bias", "postnet.convolutions.2.1.running_mean", "postnet.convolutions.2.1.running_var", "postnet.convolutions.3.0.conv.weight", "postnet.convolutions.3.0.conv.bias", "postnet.convolutions.3.1.weight", "postnet.convolutions.3.1.bias", "postnet.convolutions.3.1.running_mean", "postnet.convolutions.3.1.running_var", "postnet.convolutions.4.0.conv.weight", "postnet.convolutions.4.0.conv.bias", "postnet.convolutions.4.1.weight", "postnet.convolutions.4.1.bias", "postnet.convolutions.4.1.running_mean", "postnet.convolutions.4.1.running_var".
	Unexpected key(s) in state_dict: "module.embedding.weight", "module.encoder.convolutions.0.0.conv.weight", "module.encoder.convolutions.0.0.conv.bias", "module.encoder.convolutions.0.1.weight", "module.encoder.convolutions.0.1.bias", "module.encoder.convolutions.0.1.running_mean", "module.encoder.convolutions.0.1.running_var", "module.encoder.convolutions.0.1.num_batches_tracked", "module.encoder.convolutions.1.0.conv.weight", "module.encoder.convolutions.1.0.conv.bias", "module.encoder.convolutions.1.1.weight", "module.encoder.convolutions.1.1.bias", "module.encoder.convolutions.1.1.running_mean", "module.encoder.convolutions.1.1.running_var", "module.encoder.convolutions.1.1.num_batches_tracked", "module.encoder.convolutions.2.0.conv.weight", "module.encoder.convolutions.2.0.conv.bias", "module.encoder.convolutions.2.1.weight", "module.encoder.convolutions.2.1.bias", "module.encoder.convolutions.2.1.running_mean", "module.encoder.convolutions.2.1.running_var", "module.encoder.convolutions.2.1.num_batches_tracked", "module.encoder.lstm.weight_ih_l0", "module.encoder.lstm.weight_hh_l0", "module.encoder.lstm.bias_ih_l0", "module.encoder.lstm.bias_hh_l0", "module.encoder.lstm.weight_ih_l0_reverse", "module.encoder.lstm.weight_hh_l0_reverse", "module.encoder.lstm.bias_ih_l0_reverse", "module.encoder.lstm.bias_hh_l0_reverse", "module.decoder.prenet.layers.0.linear_layer.weight", "module.decoder.prenet.layers.1.linear_layer.weight", "module.decoder.attention_rnn.weight_ih", "module.decoder.attention_rnn.weight_hh", "module.decoder.attention_rnn.bias_ih", "module.decoder.attention_rnn.bias_hh", "module.decoder.attention_layer.query_layer.linear_layer.weight", "module.decoder.attention_layer.memory_layer.linear_layer.weight", "module.decoder.attention_layer.v.linear_layer.weight", "module.decoder.attention_layer.location_layer.location_conv.conv.weight", "module.decoder.attention_layer.location_layer.location_dense.linear_layer.weight", "module.decoder.decoder_rnn.weight_ih", "module.decoder.decoder_rnn.weight_hh", "module.decoder.decoder_rnn.bias_ih", "module.decoder.decoder_rnn.bias_hh", "module.decoder.linear_projection.linear_layer.weight", "module.decoder.linear_projection.linear_layer.bias", "module.decoder.gate_layer.linear_layer.weight", "module.decoder.gate_layer.linear_layer.bias", "module.postnet.convolutions.0.0.conv.weight", "module.postnet.convolutions.0.0.conv.bias", "module.postnet.convolutions.0.1.weight", "module.postnet.convolutions.0.1.bias", "module.postnet.convolutions.0.1.running_mean", "module.postnet.convolutions.0.1.running_var", "module.postnet.convolutions.0.1.num_batches_tracked", "module.postnet.convolutions.1.0.conv.weight", "module.postnet.convolutions.1.0.conv.bias", "module.postnet.convolutions.1.1.weight", "module.postnet.convolutions.1.1.bias", "module.postnet.convolutions.1.1.running_mean", "module.postnet.convolutions.1.1.running_var", "module.postnet.convolutions.1.1.num_batches_tracked", "module.postnet.convolutions.2.0.conv.weight", "module.postnet.convolutions.2.0.conv.bias", "module.postnet.convolutions.2.1.weight", "module.postnet.convolutions.2.1.bias", "module.postnet.convolutions.2.1.running_mean", "module.postnet.convolutions.2.1.running_var", "module.postnet.convolutions.2.1.num_batches_tracked", "module.postnet.convolutions.3.0.conv.weight", "module.postnet.convolutions.3.0.conv.bias", "module.postnet.convolutions.3.1.weight", "module.postnet.convolutions.3.1.bias", "module.postnet.convolutions.3.1.running_mean", "module.postnet.convolutions.3.1.running_var", "module.postnet.convolutions.3.1.num_batches_tracked", "module.postnet.convolutions.4.0.conv.weight", "module.postnet.convolutions.4.0.conv.bias", "module.postnet.convolutions.4.1.weight", "module.postnet.convolutions.4.1.bias", "module.postnet.convolutions.4.1.running_mean", "module.postnet.convolutions.4.1.running_var", "module.postnet.convolutions.4.1.num_batches_tracked".
/scratch/md5121/okhatisathi/tacotron2/stft.py:67: FutureWarning: Pass size=1024 as keyword args. From version 0.10 passing these as positional arguments will result in an error
  fft_window = pad_center(fft_window, filter_length)
/scratch/md5121/okhatisathi/tacotron2/layers.py:51: FutureWarning: Pass sr=22050, n_fft=1024, n_mels=80, fmin=0.0, fmax=8000.0 as keyword args. From version 0.10 passing these as positional arguments will result in an error
  sampling_rate, filter_length, n_mel_channels, mel_fmin, mel_fmax)
Traceback (most recent call last):
  File "<ipython-input-11-324c4e357ba3>", line 37, in <module>
    use_wandb=use_wandb
  File "/scratch/md5121/okhatisathi/tacotron2/train.py", line 200, in train
  File "/scratch/md5121/okhatisathi/tacotron2/train.py", line 103, in load_checkpoint
    #     checkpoint_dict = torch.load(checkpoint_path, map_location='cpu')
  File "/home/md5121/.conda/envs/t2env/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1483, in load_state_dict
    self.__class__.__name__, "\n\t".join(error_msgs)))
RuntimeError: Error(s) in loading state_dict for Tacotron2:
	Missing key(s) in state_dict: "embedding.weight", "encoder.convolutions.0.0.conv.weight", "encoder.convolutions.0.0.conv.bias", "encoder.convolutions.0.1.weight", "encoder.convolutions.0.1.bias", "encoder.convolutions.0.1.running_mean", "encoder.convolutions.0.1.running_var", "encoder.convolutions.1.0.conv.weight", "encoder.convolutions.1.0.conv.bias", "encoder.convolutions.1.1.weight", "encoder.convolutions.1.1.bias", "encoder.convolutions.1.1.running_mean", "encoder.convolutions.1.1.running_var", "encoder.convolutions.2.0.conv.weight", "encoder.convolutions.2.0.conv.bias", "encoder.convolutions.2.1.weight", "encoder.convolutions.2.1.bias", "encoder.convolutions.2.1.running_mean", "encoder.convolutions.2.1.running_var", "encoder.lstm.weight_ih_l0", "encoder.lstm.weight_hh_l0", "encoder.lstm.bias_ih_l0", "encoder.lstm.bias_hh_l0", "encoder.lstm.weight_ih_l0_reverse", "encoder.lstm.weight_hh_l0_reverse", "encoder.lstm.bias_ih_l0_reverse", "encoder.lstm.bias_hh_l0_reverse", "decoder.prenet.layers.0.linear_layer.weight", "decoder.prenet.layers.1.linear_layer.weight", "decoder.attention_rnn.weight_ih", "decoder.attention_rnn.weight_hh", "decoder.attention_rnn.bias_ih", "decoder.attention_rnn.bias_hh", "decoder.attention_layer.query_layer.linear_layer.weight", "decoder.attention_layer.memory_layer.linear_layer.weight", "decoder.attention_layer.v.linear_layer.weight", "decoder.attention_layer.location_layer.location_conv.conv.weight", "decoder.attention_layer.location_layer.location_dense.linear_layer.weight", "decoder.decoder_rnn.weight_ih", "decoder.decoder_rnn.weight_hh", "decoder.decoder_rnn.bias_ih", "decoder.decoder_rnn.bias_hh", "decoder.linear_projection.linear_layer.weight", "decoder.linear_projection.linear_layer.bias", "decoder.gate_layer.linear_layer.weight", "decoder.gate_layer.linear_layer.bias", "postnet.convolutions.0.0.conv.weight", "postnet.convolutions.0.0.conv.bias", "postnet.convolutions.0.1.weight", "postnet.convolutions.0.1.bias", "postnet.convolutions.0.1.running_mean", "postnet.convolutions.0.1.running_var", "postnet.convolutions.1.0.conv.weight", "postnet.convolutions.1.0.conv.bias", "postnet.convolutions.1.1.weight", "postnet.convolutions.1.1.bias", "postnet.convolutions.1.1.running_mean", "postnet.convolutions.1.1.running_var", "postnet.convolutions.2.0.conv.weight", "postnet.convolutions.2.0.conv.bias", "postnet.convolutions.2.1.weight", "postnet.convolutions.2.1.bias", "postnet.convolutions.2.1.running_mean", "postnet.convolutions.2.1.running_var", "postnet.convolutions.3.0.conv.weight", "postnet.convolutions.3.0.conv.bias", "postnet.convolutions.3.1.weight", "postnet.convolutions.3.1.bias", "postnet.convolutions.3.1.running_mean", "postnet.convolutions.3.1.running_var", "postnet.convolutions.4.0.conv.weight", "postnet.convolutions.4.0.conv.bias", "postnet.convolutions.4.1.weight", "postnet.convolutions.4.1.bias", "postnet.convolutions.4.1.running_mean", "postnet.convolutions.4.1.running_var".
	Unexpected key(s) in state_dict: "module.embedding.weight", "module.encoder.convolutions.0.0.conv.weight", "module.encoder.convolutions.0.0.conv.bias", "module.encoder.convolutions.0.1.weight", "module.encoder.convolutions.0.1.bias", "module.encoder.convolutions.0.1.running_mean", "module.encoder.convolutions.0.1.running_var", "module.encoder.convolutions.0.1.num_batches_tracked", "module.encoder.convolutions.1.0.conv.weight", "module.encoder.convolutions.1.0.conv.bias", "module.encoder.convolutions.1.1.weight", "module.encoder.convolutions.1.1.bias", "module.encoder.convolutions.1.1.running_mean", "module.encoder.convolutions.1.1.running_var", "module.encoder.convolutions.1.1.num_batches_tracked", "module.encoder.convolutions.2.0.conv.weight", "module.encoder.convolutions.2.0.conv.bias", "module.encoder.convolutions.2.1.weight", "module.encoder.convolutions.2.1.bias", "module.encoder.convolutions.2.1.running_mean", "module.encoder.convolutions.2.1.running_var", "module.encoder.convolutions.2.1.num_batches_tracked", "module.encoder.lstm.weight_ih_l0", "module.encoder.lstm.weight_hh_l0", "module.encoder.lstm.bias_ih_l0", "module.encoder.lstm.bias_hh_l0", "module.encoder.lstm.weight_ih_l0_reverse", "module.encoder.lstm.weight_hh_l0_reverse", "module.encoder.lstm.bias_ih_l0_reverse", "module.encoder.lstm.bias_hh_l0_reverse", "module.decoder.prenet.layers.0.linear_layer.weight", "module.decoder.prenet.layers.1.linear_layer.weight", "module.decoder.attention_rnn.weight_ih", "module.decoder.attention_rnn.weight_hh", "module.decoder.attention_rnn.bias_ih", "module.decoder.attention_rnn.bias_hh", "module.decoder.attention_layer.query_layer.linear_layer.weight", "module.decoder.attention_layer.memory_layer.linear_layer.weight", "module.decoder.attention_layer.v.linear_layer.weight", "module.decoder.attention_layer.location_layer.location_conv.conv.weight", "module.decoder.attention_layer.location_layer.location_dense.linear_layer.weight", "module.decoder.decoder_rnn.weight_ih", "module.decoder.decoder_rnn.weight_hh", "module.decoder.decoder_rnn.bias_ih", "module.decoder.decoder_rnn.bias_hh", "module.decoder.linear_projection.linear_layer.weight", "module.decoder.linear_projection.linear_layer.bias", "module.decoder.gate_layer.linear_layer.weight", "module.decoder.gate_layer.linear_layer.bias", "module.postnet.convolutions.0.0.conv.weight", "module.postnet.convolutions.0.0.conv.bias", "module.postnet.convolutions.0.1.weight", "module.postnet.convolutions.0.1.bias", "module.postnet.convolutions.0.1.running_mean", "module.postnet.convolutions.0.1.running_var", "module.postnet.convolutions.0.1.num_batches_tracked", "module.postnet.convolutions.1.0.conv.weight", "module.postnet.convolutions.1.0.conv.bias", "module.postnet.convolutions.1.1.weight", "module.postnet.convolutions.1.1.bias", "module.postnet.convolutions.1.1.running_mean", "module.postnet.convolutions.1.1.running_var", "module.postnet.convolutions.1.1.num_batches_tracked", "module.postnet.convolutions.2.0.conv.weight", "module.postnet.convolutions.2.0.conv.bias", "module.postnet.convolutions.2.1.weight", "module.postnet.convolutions.2.1.bias", "module.postnet.convolutions.2.1.running_mean", "module.postnet.convolutions.2.1.running_var", "module.postnet.convolutions.2.1.num_batches_tracked", "module.postnet.convolutions.3.0.conv.weight", "module.postnet.convolutions.3.0.conv.bias", "module.postnet.convolutions.3.1.weight", "module.postnet.convolutions.3.1.bias", "module.postnet.convolutions.3.1.running_mean", "module.postnet.convolutions.3.1.running_var", "module.postnet.convolutions.3.1.num_batches_tracked", "module.postnet.convolutions.4.0.conv.weight", "module.postnet.convolutions.4.0.conv.bias", "module.postnet.convolutions.4.1.weight", "module.postnet.convolutions.4.1.bias", "module.postnet.convolutions.4.1.running_mean", "module.postnet.convolutions.4.1.running_var", "module.postnet.convolutions.4.1.num_batches_tracked".